{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeyBurlD24-k",
        "outputId": "4929f060-3324-4f94-f133-14a94fd9896a"
      },
      "source": [
        "\n",
        "!pip install -U nltk\n",
        "!pip install matplotlib==3.4.1\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import statistics\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import string\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method7\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib==3.4.1 in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.1) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.4.1) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvoSsamMtFFH",
        "outputId": "26e2fd93-51dd-4c28-9afb-fd4a09d553eb"
      },
      "source": [
        "! gdown --id 1_C260zgutx-BXmMUkDYfhJTqlDLCsHPI\n",
        "! unzip FinalDataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_C260zgutx-BXmMUkDYfhJTqlDLCsHPI\n",
            "To: /content/FinalDataset.zip\n",
            "100% 163k/163k [00:00<00:00, 55.0MB/s]\n",
            "Archive:  FinalDataset.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n",
            "  inflating: val.csv                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## Change the name of read_csv() in the following order\n",
        "  1.   train.csv\n",
        "  2.   val.csv\n",
        "  3.   test.csv\n"
      ],
      "metadata": {
        "id": "85f0RRWlKXEV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYYN7jSt344W",
        "outputId": "a7364c88-d765-45a9-c1b5-5744a723d8b0"
      },
      "source": [
        "\n",
        "dataset = pd.read_csv('val.csv')\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              sentence1  \\\n",
            "0                      রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
            "1                      রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
            "2                      রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
            "3                      রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
            "4                      রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
            "...                                                 ...   \n",
            "1469                তুরস্ক: যুদ্ধাপরাধ করেছে আর্মেনিয়া   \n",
            "1470                তুরস্ক: যুদ্ধাপরাধ করেছে আর্মেনিয়া   \n",
            "1471  আজারবাইজানের সঙ্গে যুদ্ধে ৬০৪ আর্মেনীয় যোদ্ধা...   \n",
            "1472  আজারবাইজানের সঙ্গে যুদ্ধে ৬০৪ আর্মেনীয় যোদ্ধা...   \n",
            "1473  আর্মেনিয়া প্রথমে যুদ্ধবিরতি লঙ্ঘন করেছে : আজার...   \n",
            "\n",
            "                                              sentence2  label  \n",
            "0               আদালত থেকে আর বাড়ি যাওয়া হলো না মিন্নির      0  \n",
            "1      রিফাত হত্যায় স্ত্রী মিন্নিসহ ৬ জনের ফাঁসির রায়      0  \n",
            "2                মিন্নির প্রতি অবিচার করা হয়েছে : বাবা      0  \n",
            "3            রিফাত হত্যা মামলা : কিছুক্ষণের মধ্যেই রায়      0  \n",
            "4                 আদালতে এসেছেন বিচারক মো. আছাদুজ্জামান      0  \n",
            "...                                                 ...    ...  \n",
            "1469  আর্মেনিয়া প্রথমে যুদ্ধবিরতি লঙ্ঘন করেছে : আজার...      0  \n",
            "1470           আর্মেনিয়ার আরও ৬ গ্রাম দখল আজারবাইজানের      0  \n",
            "1471  আর্মেনিয়া প্রথমে যুদ্ধবিরতি লঙ্ঘন করেছে : আজার...      0  \n",
            "1472           আর্মেনিয়ার আরও ৬ গ্রাম দখল আজারবাইজানের      0  \n",
            "1473           আর্মেনিয়ার আরও ৬ গ্রাম দখল আজারবাইজানের      0  \n",
            "\n",
            "[1474 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRJvfh9xUrLW",
        "outputId": "478a7ce5-054e-4e24-f24f-dbdc6ed20ed7"
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence1', 'sentence2', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the number of datas and the avg Meteor score of the current dataset"
      ],
      "metadata": {
        "id": "yT0EFsUjK2iK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFy9Ku8z4Dj2",
        "outputId": "7afe9461-8620-435e-ab47-198b8e3529e8"
      },
      "source": [
        "\n",
        "total_rows = dataset.shape[0]\n",
        "\n",
        "print(total_rows)\n",
        "\n",
        "ref_list = list()\n",
        "\n",
        "cand_list = list()\n",
        "\n",
        "count = 0\n",
        "\n",
        "tot_score = list()\n",
        "\n",
        "for i in range(total_rows):\n",
        "\n",
        "\n",
        "\n",
        "  sentence = dataset[\"sentence1\"][i]\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence = sentence.replace('।', '')\n",
        "  ref = nltk.tokenize.WhitespaceTokenizer().tokenize(sentence)\n",
        "  ref1 = [ref]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  sentence2 = dataset[\"sentence2\"][i]\n",
        "  sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence2 = sentence2.replace('।', '')\n",
        "\n",
        "  cand = nltk.tokenize.WhitespaceTokenizer().tokenize(sentence2)\n",
        "\n",
        "  score1 = nltk.translate.meteor_score.meteor_score(ref1,cand)\n",
        "\n",
        "\n",
        "  sentence3 = dataset[\"sentence2\"][i]\n",
        "  sentence3 = sentence3.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence3 = sentence3.replace('।', '')\n",
        "  ref2 = nltk.tokenize.WhitespaceTokenizer().tokenize(sentence3)\n",
        "  ref3 = [ref2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  sentence4 = dataset[\"sentence1\"][i]\n",
        "  sentence4 = sentence4.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence4 = sentence4.replace('।', '')\n",
        "\n",
        "  cand2 = nltk.tokenize.WhitespaceTokenizer().tokenize(sentence4)\n",
        "\n",
        "  score2 = nltk.translate.meteor_score.meteor_score(ref3,cand2)\n",
        "\n",
        "\n",
        "  avg_s = (score1+score2)/2\n",
        "  b=np.round(avg_s,1)\n",
        "\n",
        "  # if(b == 0.1):\n",
        "    # print(\"---> 1 \",sentence4)\n",
        "    # print(\"----> 2 \", sentence3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  tot_score.append(avg_s)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(b, return_counts=True)\n",
        "\n",
        "\n",
        "# print(counts_elements)\n",
        "# print(unique_elements)\n",
        "xxi = unique_elements.tolist()\n",
        "\n",
        "ooi = list(map(str, xxi))\n",
        "\n",
        "yyi = counts_elements.tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(tot_score)\n",
        "dataset.insert(3, 'Meteor_Score', tot_score)\n",
        "average = statistics.mean(tot_score)\n",
        "\n",
        "print(average*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1474\n",
            "15.146019984390307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-PgFEjbBXT8L",
        "outputId": "0fd8d29b-5efc-4888-ea3b-e78a41ee4d68"
      },
      "source": [
        "# print(dataset)\n",
        "# dataset.to_csv('After_Adding_Meteor_fail.csv', index=False)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          sentence1  \\\n",
              "0  রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
              "1  রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
              "2  রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
              "3  রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
              "4  রায়ের পর হাসছিলেন রিফাত ফরাজীরা   \n",
              "\n",
              "                                          sentence2  label  Meteor_Score  \n",
              "0           আদালত থেকে আর বাড়ি যাওয়া হলো না মিন্নির      0      0.000000  \n",
              "1  রিফাত হত্যায় স্ত্রী মিন্নিসহ ৬ জনের ফাঁসির রায়      0      0.079637  \n",
              "2            মিন্নির প্রতি অবিচার করা হয়েছে : বাবা      0      0.000000  \n",
              "3        রিফাত হত্যা মামলা : কিছুক্ষণের মধ্যেই রায়      0      0.091392  \n",
              "4             আদালতে এসেছেন বিচারক মো. আছাদুজ্জামান      0      0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73ce7391-5e1f-48c3-9e55-f217548a908d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "      <th>Meteor_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>রায়ের পর হাসছিলেন রিফাত ফরাজীরা</td>\n",
              "      <td>আদালত থেকে আর বাড়ি যাওয়া হলো না মিন্নির</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>রায়ের পর হাসছিলেন রিফাত ফরাজীরা</td>\n",
              "      <td>রিফাত হত্যায় স্ত্রী মিন্নিসহ ৬ জনের ফাঁসির রায়</td>\n",
              "      <td>0</td>\n",
              "      <td>0.079637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>রায়ের পর হাসছিলেন রিফাত ফরাজীরা</td>\n",
              "      <td>মিন্নির প্রতি অবিচার করা হয়েছে : বাবা</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>রায়ের পর হাসছিলেন রিফাত ফরাজীরা</td>\n",
              "      <td>রিফাত হত্যা মামলা : কিছুক্ষণের মধ্যেই রায়</td>\n",
              "      <td>0</td>\n",
              "      <td>0.091392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>রায়ের পর হাসছিলেন রিফাত ফরাজীরা</td>\n",
              "      <td>আদালতে এসেছেন বিচারক মো. আছাদুজ্জামান</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73ce7391-5e1f-48c3-9e55-f217548a908d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73ce7391-5e1f-48c3-9e55-f217548a908d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73ce7391-5e1f-48c3-9e55-f217548a908d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell gives the threshold score and threshold index for the highest F1 score"
      ],
      "metadata": {
        "id": "9kVeJypTKLVq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5kx2WFlZhmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3d1fa1-914c-48da-8d68-601fc29c6f58"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "\n",
        "F1_Score = list()\n",
        "\n",
        "total_rows = dataset.shape[0]\n",
        "\n",
        "f_s = 0\n",
        "\n",
        "Fsc = 0.0\n",
        "\n",
        "dataset\n",
        "label_list = dataset['label'].tolist()\n",
        "\n",
        "while(Fsc<=1.0):\n",
        "\n",
        "  compare_list = list()\n",
        "  for i in range(total_rows):\n",
        "    meteor_score = dataset[\"Meteor_Score\"][i]\n",
        "    if (meteor_score >= Fsc):\n",
        "      filtered_score = 1\n",
        "\n",
        "      compare_list.append(filtered_score)\n",
        "    else:\n",
        "\n",
        "      filtered_score = 0\n",
        "      compare_list.append(filtered_score)\n",
        "\n",
        "  Fsc += 0.001\n",
        "  f_s = f1_score(label_list,compare_list,average='weighted')\n",
        "  F1_Score.append(f_s)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(F1_Score)\n",
        "print(len(F1_Score))\n",
        "\n",
        "max_value = max(F1_Score)\n",
        "\n",
        "print(max_value)\n",
        "\n",
        "max_index = F1_Score.index(max_value)\n",
        "\n",
        "print(max_index)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23686350172416945, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.737732986885797, 0.7377934165622517, 0.7377934165622517, 0.7377934165622517, 0.7385007294516829, 0.7385007294516829, 0.7385007294516829, 0.7392076486035608, 0.7399141759566766, 0.7399717492052239, 0.7400283682545298, 0.7407332567891145, 0.7428456339419269, 0.7442519975635256, 0.7484621956309314, 0.7498626816827134, 0.750562387041394, 0.7520062035380612, 0.7520062035380612, 0.7598144203270072, 0.7598144203270072, 0.7611984582192293, 0.7627070188408491, 0.765460557017019, 0.7649026829295403, 0.7655881029533333, 0.7690511400801544, 0.7738943863481259, 0.7738943863481259, 0.7806837903973682, 0.7860851779096377, 0.7860851779096377, 0.7941395188379871, 0.7941395188379871, 0.7941395188379871, 0.7981101834346243, 0.8040473413878315, 0.8040473413878315, 0.8040473413878315, 0.8046941467717369, 0.8053584183230951, 0.8178299206866776, 0.8178299206866776, 0.815641980507309, 0.817619960602683, 0.817619960602683, 0.817619960602683, 0.8221636687758336, 0.8232521486634327, 0.8232521486634327, 0.8232521486634327, 0.8225547025234059, 0.8225547025234059, 0.8231703860989631, 0.8231703860989631, 0.8289015931119936, 0.8289015931119936, 0.8289015931119936, 0.8288551784947116, 0.8306279134942169, 0.83128310793556, 0.83128310793556, 0.8319383293126474, 0.8303688012626633, 0.83102327127395, 0.83102327127395, 0.8322228931879425, 0.8322228931879425, 0.8322228931879425, 0.8334188211728827, 0.8326493045858699, 0.8326493045858699, 0.8326493045858699, 0.8326493045858699, 0.8333031945926168, 0.8315697446588538, 0.8315697446588538, 0.8315697446588538, 0.8313103902376949, 0.8305912741050249, 0.8305912741050249, 0.8283618840578211, 0.8283618840578211, 0.8303174495158153, 0.8301041612685568, 0.8301041612685568, 0.8301041612685568, 0.8301041612685568, 0.8269760511755513, 0.8269760511755513, 0.8295016767280323, 0.8295016767280323, 0.8295016767280323, 0.8295016767280323, 0.8257653879363513, 0.8270656491845629, 0.8270656491845629, 0.8248635949984164, 0.8248635949984164, 0.8248635949984164, 0.8253411884548327, 0.8238670209844343, 0.8238670209844343, 0.8231291049081957, 0.8231291049081957, 0.8231291049081957, 0.8223002724899744, 0.8229490947136335, 0.8224842811276162, 0.8224842811276162, 0.8224842811276162, 0.8224842811276162, 0.8224842811276162, 0.8224842811276162, 0.8201526109915076, 0.8201526109915076, 0.8201526109915076, 0.8201526109915076, 0.8184569968594291, 0.8184569968594291, 0.8183547332963349, 0.8183547332963349, 0.8176044321001543, 0.8152432067315311, 0.8152432067315311, 0.8152432067315311, 0.8152432067315311, 0.8152432067315311, 0.8152432067315311, 0.8152432067315311, 0.8105987392359183, 0.8105987392359183, 0.8105987392359183, 0.80972564359172, 0.808965625867746, 0.808965625867746, 0.808965625867746, 0.808965625867746, 0.808965625867746, 0.808965625867746, 0.8074435788248799, 0.8074435788248799, 0.8074435788248799, 0.8059188284366602, 0.8020949569575101, 0.8020949569575101, 0.8005605422450108, 0.8005605422450108, 0.8005605422450108, 0.8005605422450108, 0.7990233077526456, 0.7967121113163179, 0.7943944216155009, 0.7928456431936802, 0.7912939117514183, 0.7912939117514183, 0.7911550977749571, 0.7911550977749571, 0.7911550977749571, 0.7895983272889348, 0.7895983272889348, 0.7878944425827836, 0.7878944425827836, 0.7853974129447318, 0.7806725305709644, 0.7806725305709644, 0.7806725305709644, 0.7806725305709644, 0.7806725305709644, 0.7781397523347523, 0.7787731738679207, 0.7787731738679207, 0.7794068052411327, 0.7792458773249757, 0.7784502750124083, 0.7784502750124083, 0.7784502750124083, 0.7784502750124083, 0.7782869694551885, 0.7742905560541616, 0.7742905560541616, 0.7734887118042428, 0.7734887118042428, 0.7734887118042428, 0.7734887118042428, 0.7718824313655039, 0.7718824313655039, 0.7702726694818958, 0.7700962935012816, 0.7683004412951171, 0.7683004412951171, 0.7683004412951171, 0.7683004412951171, 0.7683004412951171, 0.7683004412951171, 0.7658664701983489, 0.7658664701983489, 0.7656812449471546, 0.7663093854959517, 0.7663093854959517, 0.7657451151959245, 0.7657451151959245, 0.7649265544973779, 0.7649265544973779, 0.7649265544973779, 0.7649265544973779, 0.7641070548494592, 0.7632866121474019, 0.7645408399800746, 0.7645408399800746, 0.7637187409978043, 0.7637187409978043, 0.7637187409978043, 0.7620716730771783, 0.760641559395667, 0.760641559395667, 0.760641559395667, 0.760641559395667, 0.7596055829090351, 0.7587732463526954, 0.760439393120916, 0.7593914564201599, 0.7593914564201599, 0.7593914564201599, 0.7585531874654929, 0.7585531874654929, 0.7585531874654929, 0.7585531874654929, 0.7585531874654929, 0.7585531874654929, 0.7585531874654929, 0.7574974556803122, 0.7574974556803122, 0.7558128942777209, 0.7558128942777209, 0.7555920482966912, 0.7555920482966912, 0.7539003858252685, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.7522044593945941, 0.752826158516769, 0.752826158516769, 0.752826158516769, 0.752826158516769, 0.7519761834624662, 0.7519761834624662, 0.7519761834624662, 0.7448950058496879, 0.7440335719222446, 0.7431710058189597, 0.7431710058189597, 0.7414424575554452, 0.7411924595736588, 0.7411924595736588, 0.7411924595736588, 0.7411924595736588, 0.7394561394072557, 0.7394561394072557, 0.7394561394072557, 0.7368429149419792, 0.7368429149419792, 0.7359694882357575, 0.7350948771559533, 0.7342190766131239, 0.7333420814972363, 0.7333420814972363, 0.7324638866775496, 0.7324638866775496, 0.7324638866775496, 0.7324638866775496, 0.7315844870024906, 0.7315844870024906, 0.7315844870024906, 0.7315844870024906, 0.7315844870024906, 0.729822052375075, 0.7268910038135299, 0.7260025435087198, 0.7260025435087198, 0.7260025435087198, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7239364982717851, 0.7212507240059569, 0.7212507240059569, 0.7212507240059569, 0.7203529035465245, 0.7209580619465493, 0.7200584481568878, 0.7200584481568878, 0.7200584481568878, 0.7200584481568878, 0.7100757433708333, 0.7097170514443124, 0.7097170514443124, 0.7087951693710086, 0.7087951693710086, 0.7087951693710086, 0.7087951693710086, 0.7087951693710086, 0.7072145286424533, 0.7062858989654693, 0.7053558414738365, 0.7053558414738365, 0.7044243500205222, 0.7025570405056165, 0.7025570405056165, 0.7025570405056165, 0.699745166284205, 0.699745166284205, 0.699745166284205, 0.699745166284205, 0.699745166284205, 0.7003377397354632, 0.7003377397354632, 0.7003377397354632, 0.6956187959722917, 0.694670512527387, 0.694670512527387, 0.693720715749312, 0.6916658169453539, 0.6916658169453539, 0.6907064745399867, 0.6868533996511401, 0.6868533996511401, 0.6868533996511401, 0.6868533996511401, 0.6868533996511401, 0.6868533996511401, 0.6874373499308503, 0.6874373499308503, 0.6874373499308503, 0.6874373499308503, 0.6874373499308503, 0.6874373499308503, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6831628745901446, 0.6833478165861194, 0.6774452461671018, 0.6774452461671018, 0.6774452461671018, 0.6774452461671018, 0.6754642661860305, 0.6744712200001135, 0.6744712200001135, 0.6734764597608773, 0.6734764597608773, 0.6734764597608773, 0.6734764597608773, 0.6734764597608773, 0.6734764597608773, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6710540321647577, 0.6700516171155655, 0.6700516171155655, 0.6700516171155655, 0.6660243194052788, 0.6639999794697218, 0.6639999794697218, 0.6615150128892162, 0.6615150128892162, 0.6615150128892162, 0.6563910737086347, 0.6563910737086347, 0.6563910737086347, 0.6563910737086347, 0.6553607034476118, 0.6543284532104272, 0.6512203394855999, 0.6512203394855999, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6480950048896882, 0.6470493602542507, 0.6470493602542507, 0.6470493602542507, 0.6470493602542507, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6460017681259271, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6428472202845107, 0.6417917514699231, 0.6417917514699231, 0.6417917514699231, 0.6338185583637076, 0.6327439484021845, 0.6327439484021845, 0.6311290267178739, 0.6311290267178739, 0.6311290267178739, 0.6289633412602997, 0.6289633412602997, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.627877322596307, 0.6191116854005356, 0.6191116854005356, 0.6191116854005356, 0.6168983942473871, 0.6168983942473871, 0.6168983942473871, 0.6168983942473871, 0.6168983942473871, 0.6157884119394147, 0.6146761917365422, 0.6146761917365422, 0.6146761917365422, 0.6124449971084802, 0.6124449971084802, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.608475655914468, 0.6073464449931526, 0.6073464449931526, 0.6005219493208727, 0.6005219493208727, 0.5993762281456297, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5970775691052113, 0.5947692142046357, 0.593611372981131, 0.5912883068100274, 0.5912883068100274, 0.5912883068100274, 0.5912883068100274, 0.59012305920887, 0.59012305920887, 0.59012305920887, 0.59012305920887, 0.59012305920887, 0.5877850778800575, 0.5877850778800575, 0.5866123211279047, 0.5823909297181764, 0.5823909297181764, 0.5823909297181764, 0.5823909297181764, 0.581204230881691, 0.581204230881691, 0.581204230881691, 0.5800149396945329, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5788230441164305, 0.5776285320406284, 0.5776285320406284, 0.5764313912934115, 0.5764313912934115, 0.5764313912934115, 0.5764313912934115, 0.5752316096336237, 0.5728240742716009, 0.5728240742716009, 0.5728240742716009, 0.570405826657995, 0.5691926544234631, 0.5691926544234631, 0.5691926544234631, 0.5691926544234631, 0.5679767663857591, 0.5679767663857591, 0.5618561411922732, 0.5618561411922732, 0.5581503507927915, 0.5581503507927915, 0.5569094391277721, 0.5569094391277721, 0.5569094391277721, 0.5519171939178101, 0.5506619150727737, 0.5506619150727737, 0.5506619150727737, 0.5506619150727737, 0.5506619150727737, 0.5494037217762073, 0.5494037217762073, 0.5494037217762073, 0.5481426001730028, 0.5481426001730028, 0.5481426001730028, 0.5481426001730028, 0.5468785363283462, 0.5456115162271263, 0.5456115162271263, 0.5456115162271263, 0.54434152577334, 0.5430685507894882, 0.5430685507894882, 0.5430685507894882, 0.5430685507894882, 0.5430685507894882, 0.5417925770159724, 0.5417925770159724, 0.5366584059253183, 0.5366584059253183, 0.5366584059253183, 0.5366584059253183, 0.5366584059253183, 0.5366584059253183, 0.5366584059253183, 0.5353672213928052, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5340729507542502, 0.5327755791578993, 0.5327755791578993, 0.5327755791578993, 0.5327755791578993, 0.5314750916648456, 0.5314750916648456, 0.5314750916648456, 0.5314750916648456, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5301714732483719, 0.5288647087932867, 0.5288647087932867, 0.5275547830952563, 0.5275547830952563, 0.5275547830952563, 0.5262416808601285, 0.5262416808601285, 0.5262416808601285, 0.5262416808601285, 0.5249253867032524, 0.5249253867032524, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5222831606290244, 0.5209571974836561, 0.5209571974836561, 0.5209571974836561, 0.5200535378566528, 0.5200535378566528, 0.5173820216432147, 0.5146972559039188, 0.5133498638894819, 0.5133498638894819, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5119991106108701, 0.5106449795687752, 0.5106449795687752, 0.5106449795687752, 0.5092874541641151, 0.5092874541641151, 0.5092874541641151, 0.5092874541641151, 0.5092874541641151, 0.5092874541641151, 0.5092874541641151, 0.5079265176972613, 0.5079265176972613, 0.5038230734026247, 0.5038230734026247, 0.5038230734026247, 0.5024483236523339, 0.5024483236523339, 0.5024483236523339, 0.5024483236523339, 0.5024483236523339, 0.5024483236523339, 0.49968831854397666, 0.49968831854397666, 0.49968831854397666, 0.49968831854397666, 0.49968831854397666, 0.49968831854397666, 0.4955217854715707, 0.4955217854715707, 0.4955217854715707, 0.494125797216053, 0.494125797216053, 0.4927262073381008, 0.491322997868591, 0.491322997868591, 0.491322997868591, 0.48991615072713135, 0.4885056477211819, 0.4885056477211819, 0.4885056477211819, 0.4885056477211819, 0.4885056477211819, 0.4885056477211819, 0.48709147054516577, 0.48709147054516577, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.48567360077957317, 0.4842520198900558, 0.4842520198900558, 0.4842520198900558, 0.4842520198900558, 0.4828267092265137, 0.4828267092265137, 0.4828267092265137, 0.4828267092265137, 0.47996482339265034, 0.47996482339265034, 0.4785282103350229, 0.4785282103350229, 0.4785282103350229, 0.47708779172686866, 0.47708779172686866, 0.47708779172686866, 0.47708779172686866, 0.47708779172686866, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4756435483253137, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.4741954607660636, 0.47274350956242694, 0.47274350956242694, 0.47274350956242694, 0.47274350956242694, 0.47274350956242694, 0.47274350956242694, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.4683642773615547, 0.466896674230805, 0.466896674230805, 0.466896674230805, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.4654251081514094, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46394955888125067, 0.46098642915160676, 0.46098642915160676, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45800712049582093, 0.45651134707035546, 0.4550114662445835, 0.4550114662445835, 0.4550114662445835, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4519992975704015, 0.4504869669672361, 0.4504869669672361, 0.4504869669672361, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4474497052982415, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.4459247306379184, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.44439549746005474, 0.4428619836096388, 0.4428619836096388, 0.4428619836096388, 0.4397820245436384]\n",
            "1000\n",
            "0.8334188211728827\n",
            "106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Each of the files and note down the index that gives the highest F1 Score"
      ],
      "metadata": {
        "id": "jiR1YcIgKHdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train Threshold = 106\n",
        "# val Threshold = 165\n",
        "# test Threshold = 135.5\n",
        "(106+165)/2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKVmGENXKXAH",
        "outputId": "94c82d34-0575-4b17-8399-4cff3c1077f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135.5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpRsvtyVxp49",
        "outputId": "45a9e481-35a9-4856-de33-4e1ca2881eba"
      },
      "source": [
        "dataset\n",
        "\n",
        "total_rows = dataset.shape[0]\n",
        "\n",
        "filtered_score = 0\n",
        "\n",
        "compare_list = list()\n",
        "\n",
        "for i in range(total_rows):\n",
        "  meteor_score = dataset[\"Meteor_Score\"][i]\n",
        "\n",
        "\n",
        "  if (meteor_score >= 0.106): # Take the avg of the train and val set thresholds as test set threshold\n",
        "    filtered_score = 1\n",
        "\n",
        "    compare_list.append(filtered_score)\n",
        "  else:\n",
        "\n",
        "    filtered_score = 0\n",
        "    compare_list.append(filtered_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "dataset\n",
        "label_list = dataset['label'].tolist()\n",
        "\n",
        "print('label list : ',label_list)\n",
        "print('compare list : ', compare_list)\n",
        "\n",
        "print(classification_report(label_list,compare_list,digits=4))\n",
        "print('Precision', precision_score(label_list,compare_list, average='weighted')*100)\n",
        "print('Recall', recall_score(label_list,compare_list, average='weighted')*100)\n",
        "print('F1 Score : ',f1_score(label_list,compare_list,average='weighted')*100)\n",
        "print('Accuracy : ',accuracy_score(label_list, compare_list)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label list :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "compare list :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8435    0.8842    0.8634       872\n",
            "           1     0.8196    0.7625    0.7900       602\n",
            "\n",
            "    accuracy                         0.8345      1474\n",
            "   macro avg     0.8316    0.8233    0.8267      1474\n",
            "weighted avg     0.8338    0.8345    0.8334      1474\n",
            "\n",
            "Precision 83.37829823431085\n",
            "Recall 83.44640434192672\n",
            "F1 Score :  83.34188211728826\n",
            "Accuracy :  83.44640434192672\n"
          ]
        }
      ]
    }
  ]
}